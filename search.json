[{"title":"前向传播函数","url":"/2026/02/26/%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E5%87%BD%E6%95%B0/","content":"前向传播函数是什么？什么是前向传播？前向传播（Forward Propagation）就是神经网络处理输入数据、产生输出的过程。\n生活类比想象一个工厂流水线：\n原材料（输入图像）    ↓工位1：提取边缘特征    ↓工位2：提取纹理特征    ↓工位3：提取高级语义    ↓质检：压缩特征    ↓包装：分类结果    ↓成品（预测类别）\n\n这个从原材料到成品的整个过程，就是前向传播。\n在代码中的体现def forward(self, x):    &quot;&quot;&quot;    前向传播函数    参数:        x: 输入张量，形状为 (batch_size, 3, 64, 64)    返回:        输出张量，形状为 (batch_size, num_classes)    &quot;&quot;&quot;    # 第一层卷积特征提取    x = self.conv1(x)    # 第二层卷积特征提取    x = self.conv2(x)    # 第三层卷积特征提取    x = self.conv3(x)    # 全局平均池化，将特征图压缩为1x1    x = self.global_avg_pool(x)    # 展平张量，从 (batch_size, 64, 1, 1) 变为 (batch_size, 64)    x = torch.flatten(x, 1)    # 全连接层输出分类结果    return self.fc(x)\n\n数据流动过程# 输入：一张64x64的彩色图像input_image = torch.randn(1, 3, 64, 64)  # [1, 3, 64, 64]# 前向传播output = model(input_image)# 数据变化过程：# [1, 3, 64, 64]  ← 输入图像#   ↓ conv1 (卷积+池化)# [1, 16, 32, 32]  ← 16个特征图，尺寸减半#   ↓ conv2 (卷积+池化)# [1, 32, 16, 16]  ← 32个特征图，尺寸再减半#   ↓ conv3 (卷积+池化)# [1, 64, 8, 8]   ← 64个特征图，尺寸继续减半#   ↓ global_avg_pool# [1, 64, 1, 1]   ← 压缩为1x1#   ↓ flatten# [1, 64]          ← 展平成向量#   ↓ fc# [1, 15]          ← 15个类别的得分\n\n前向传播 vs 反向传播前向传播（Forward）:输入 → 网络 → 输出用途：预测、推理反向传播（Backward）:输出 → 计算误差 → 更新参数用途：训练、优化\n\n对比：\n# 前向传播：预测output = model(input_image)  # 调用forward函数predicted_class = torch.argmax(output, dim=1)# 反向传播：训练loss = criterion(output, target)  # 计算损失loss.backward()  # 反向传播，计算梯度optimizer.step()  # 更新参数\n\n","tags":["深度学习"]}]